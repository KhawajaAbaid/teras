{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, I'll walk you through on how to impute missing data using state of the art deep learning architectures in `Teras`.\n",
    "\n",
    "**Model**: `GAIN`\n",
    "\n",
    "**Dataset**: Gemstone dataset (from Kaggle)\n",
    "\n",
    "**Task**: Imputing missing data using GAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z  price\n",
       "0   1.52    Premium     F     VS2   62.2   58.0  7.27  7.33  4.55  13619\n",
       "1   2.03  Very Good     J     SI2   62.0   58.0  8.06  8.12  5.05  13387\n",
       "2   0.70      Ideal     G     VS1   61.2   57.0  5.69  5.73  3.50   2772"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We'll use the first 10000 instances\n",
    "# We also drop the id column since that is useless\n",
    "gem_df = pd.read_csv(\"./datasets/gemstone_dataset.csv\").drop(\"id\", axis=1)[:10000]\n",
    "gem_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [\"cut\", \"color\", \"clarity\"]\n",
    "numerical_feats = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting missing values\n",
    "Since this datasets doesn't contain any NaN values, so we'll introduce nan values ourselves to demonstrate the imputation process.\n",
    "\n",
    "For that we'll use a utility function from Teras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.utils import inject_missing_values\n",
    "\n",
    "gem_missing_df = inject_missing_values(gem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of missing values in original dataset:  0\n",
      "# of missing values in missing dataset:  10095\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that our new dataset does indeed contain nan values\n",
    "\n",
    "print(\"# of missing values in original dataset: \", gem_df.isna().sum().sum())\n",
    "print(\"# of missing values in missing dataset: \", gem_missing_df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformer and Data Sampler classes for Generative models:\n",
    "The generative architectures like `GAIN`, `PCGAIN`, `CTGAN` and `TVAE` require sophisticated data preprocessing and transformation as well as how the batches of data are generated, hence to make it easier for the users, `Teras` implements `<architecture-name>DataTransformer` and `<architecture-name>DataSampler` classes for each of these models.\n",
    "\n",
    "These can be imported from the `teras.preprocessing` module.\n",
    "For instance, for GAIN, we'll import its `GAINDataSampler` and `GAINDataTransformer` classes as follows,\n",
    "\n",
    "`from teras.preprocessing import GAINDataSampler, GAINDataTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.preprocessing import GAINDataTransformer, GAINDataSampler\n",
    "\n",
    "data_transformer = GAINDataTransformer(numerical_features=numerical_feats,\n",
    "                                       categorical_features=categorical_feats)\n",
    "gem_transformed = data_transformer.fit_transform(gem_missing_df, return_dataframe=True)\n",
    "\n",
    "data_sampler = GAINDataSampler(batch_size=1024)\n",
    "dataset = data_sampler.get_dataset(gem_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.impute import GAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we use `data_sampler.data_dim` instead of the dimensions of the original dataset. \n",
    "\n",
    "That is because during data transformation, most of the time the data dimensions are expanded by quite a lot so it's safer to use `DataSampler`'s `.data_dim` attribute.\n",
    "\n",
    "Similary we pass `metadata` using the `.get_metadata()` method of\n",
    "the `DataTransformer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_imputer = GAIN(input_dim=data_sampler.data_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For highly customized architectures like these, which employ custom loss functions, `Teras` has default values in place.\n",
    "So it's recommended to just call the `compile` method without any parameters unless you understand the underlying structure.\n",
    "\n",
    "Read more at **Section 4** of *General Guidelines and FAQs* notebook in tutorial directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_imputer.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gain_imputer.fit(dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All imputation models offered by `Teras` have a `.impute` method that can be used after training to impute the dataset with missing values.\n",
    "\n",
    "It receives the dataset with missing values, and it is recommended to pass it the instance of `DataTransformer` class that was used to transform the original data during the preprocessing step that is then used to resverse transform the generated imputed data back to original format/distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.88</td>\n",
       "      <td>717.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>63.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.06</td>\n",
       "      <td>6449.00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.03</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.52</td>\n",
       "      <td>8.667236</td>\n",
       "      <td>3.096906</td>\n",
       "      <td>10391.390496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.74</td>\n",
       "      <td>828.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.03</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.55</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4485.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  carat    cut color clarity depth table     x         y         z  \\\n",
       "0  0.38  Ideal     H     SI1  61.5  57.0  4.66       4.7      2.88   \n",
       "1  1.01   Good     G     VS1  63.7  56.0  6.37       6.4      4.06   \n",
       "2  1.03  Ideal     F     VS2  62.3  55.0  6.52  8.667236  3.096906   \n",
       "3  0.32  Ideal     F     VS2  62.1  56.0  4.43      4.38      2.74   \n",
       "4  1.03  Ideal     H     SI1  60.6  57.0  6.51      6.55      3.95   \n",
       "\n",
       "          price  \n",
       "0    717.000013  \n",
       "1    6449.00015  \n",
       "2  10391.390496  \n",
       "3    828.000017  \n",
       "4   4485.000018  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chunk = gem_transformed[500:1000]\n",
    "x_imputed = gain_imputer.impute(test_chunk,\n",
    "                                data_transformer=data_transformer,\n",
    "                                reverse_transform=True)\n",
    "\n",
    "x_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that wraps up our data imputation tutorial using Teras.\n",
    "\n",
    "If you need more help, consult documentation, and other available resources and if that still leaves you with questions, feel free to raise an issue or email me khawaja.abaid@gmail.com\n",
    "\n",
    "If you find `Teras` useful, please consider giving it a star on GitHub and sharing it with others!\n",
    "\n",
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
