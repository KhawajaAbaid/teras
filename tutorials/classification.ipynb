{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teras Classificaiton Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "In this tutorial, we'll use Teras and its both API, default and LayerFlow for classification task.\n",
    "\n",
    "**Model**: `TabTransformerClassifier`\n",
    "\n",
    "**Dataset**: Adult Income dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  ... hours-per-week  native-country income\n",
       "0   25    Private  226802  ...             40   United-States  <=50K\n",
       "1   38    Private   89814  ...             50   United-States  <=50K\n",
       "2   28  Local-gov  336951  ...             40   United-States   >50K\n",
       "\n",
       "[3 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "adult_df = pd.read_csv(\"./datasets/adult_income_dataset.csv\")\n",
    "adult_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "numerical_feats = ['age', 'hours-per-week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df.replace(\"?\", np.nan, inplace=True)\n",
    "adult_df.loc[:, categorical_feats] = adult_df.loc[:, categorical_feats].fillna(\"missing\")\n",
    "adult_df.loc[:, numerical_feats] = adult_df.loc[:, numerical_feats].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "adult_df[\"income\"] = le.fit_transform(adult_df[\"income\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You don't need to encode your categorical values except for string values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the models offered by Teras contain either `CategoricalFeatureEmbedding` layer or its variant which takes care of encoding the categorical features but it expects those values to be in integer format as Teras has removed support for string values. So only when your categorical features contain string values, you're required to manually encode those features otherwise you can just set the `enocde` parameter to True and Teras will take care of it.\n",
    "\n",
    "Here we're using `TabTransformer` model which is a **Transformer** based architecture for Classificaiton and Regression, it contains a `CategoricalFeatureEmbedding` layer which handles the categorical features. Just set the `encode` parameter to `True` and that layer will take care of encoding th.\n",
    "\n",
    "Just to make it clear, here **encoding** means converting *string values to integers/floats* and **embedding** means converting those *encoded values to dense representations* of `embeddeing_dim` dimensionality.\n",
    "\n",
    "\n",
    "**Tip**: All transformer based models contain some sort of CategoricalFeatureEmbedding layer. You can always print a model's summary or plot a model using `keras.utils.plot_model` utility function to take a look at the layers being used by a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in our case, the categorical features are of string type, we'll encode these values ourselves using `sklearn`'s `OrdinalEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "adult_df[categorical_feats] = oe.fit_transform(adult_df[categorical_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's features metadata and why do we need it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some layers like `CategoricalFeatureEmbedding` that need to be able to differentiate between feature types and apply certain operations to relevant features, need a way for that differentiation.\n",
    "\n",
    "And for that very purpose, we've introduced this concept of **Features Metadata** which is a dictionary that contains two sub dictionaries, one for categorical features and one for numerical features. \n",
    "\n",
    "The categorical features dictionary maps the categorical feature names to a tuple of feature index in the dataset and a list of unique values in that features i.e. `{feature_name: (feature_index, list_of_unique_values)}`. The list of unique values within a categorical feature is also sometimes referred to as the \"*vocabulary*\".\n",
    "It can be accessed through `features_metadata[\"categorical\"]`\n",
    "\n",
    "The numerical features dictionary maps the numerical feature names to the feature index in the dataset i.e. `{feature_name: feature_index}`. \n",
    "It can be accessed through `features_metadata[\"numerical\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why does the categorical features dictionary contains a list of unique values for each feature? \n",
    "The reason why categorical features dictionary contains a list of unqiue values for each feature is that, in case the user wants to encode the categorical values in the features, we want to have a lookup table to map these categorical values to their integer indices.\n",
    "\n",
    "And since during training the model receives data in batches and not as whole, we want to construct that lookup table on all of the categorical values, not just on values that exist within a batch of data which is what we have access to during training â€” since as you may guess the batch of data is likely to miss many of the categorical values that exist within the dataset and creating lookup table over just those values will result in unexpected and errornous results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We've got you covered!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, you don't need to worry about constructing that features metadata dictionary yourself, `Teras` offers a handy utility function just for that purpose!\n",
    "\n",
    "Just import the `get_features_metadata_for_embedding` function from the `teras.utils` module and pass it the dataset in `pandas DataFrame` format along with a list of categorical features names â€” if they don't exist in your dataset just leave it as `None`, and a list of numerial features names â€” again if they don't exist then leave it as `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.utils import get_features_metadata_for_embedding\n",
    "\n",
    "metadata = get_features_metadata_for_embedding(adult_df,\n",
    "                                               categorical_features=categorical_feats,\n",
    "                                               numerical_features=numerical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataframe to tensorflow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after you're done with preprocessing, you must convert your pandas DataFrame to a tensorflow dataset.\n",
    "\n",
    "\n",
    "If you're familiar with creating TensorFlow datasets, you can do that yourself otherwise don't worry about how to do it, `Teras` makes it easy for you do create a dataset.\n",
    "\n",
    "Just import `dataframe_to_tf_dataset` function from `teras.utils` and pass it your dataframe, along with optional `target` and `batch_size` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.utils import dataframe_to_tf_dataset\n",
    "\n",
    "adult_ds = dataframe_to_tf_dataset(dataframe=adult_df,\n",
    "                                   target=\"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's pretty much it for the preprocessing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and instantiating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teras offers two different APIs for accesing and customizing the models to satiate different levels of accessibility and flexibility needs.\n",
    "\n",
    "1. **Parametric API**: It is the default API and something you're already familiar with â€” you import the model class and specify the values for parameters that determine how the sub layers, models or blocks within the given model are constructed.\n",
    "\n",
    "    For instance, specify the `embedding_dim` parameter during instantiation of `TabTransformerClassifier` and that will be the dimensionality value used to construct/instatiate the `CategoricalFeatureEmbedding` layer. Simple enough, right?\n",
    "\n",
    "In this API, most of the parameters come with default values, so you can specify values for parameters of your choice only.\n",
    "\n",
    "\n",
    "2. **LayerFlow API**: It maximizes the flexbility while minimizing the interface. That may sound a bit contradictory at first, but let me explain. Here, instead of specifiy individual parameters specific to sub layers/models, the user instead specifies instances of those sub layers, models or blocks that are used in the given model architecture.\n",
    "\n",
    "    For instance, instead of specifying the `embedding_dim` parameter value, the user specifies an instance of `CategoricalFeatureEmbedding` layer. \n",
    "\n",
    "\n",
    "    Now in this instance, we're just passing one parameter instead of another so it may not seem like much beneficial at first glance but let me highlight how it can immensely help depending on your use case:\n",
    "\n",
    "    1. Since all you need to pass is an instance of layer, it can be any layer, there's no resitriction that it must be instance of `CategoricalFeatureEmbedding` layer â€” which means that you get complete control over not just customizing the existing layers offered by Teras but also you can design/create an Embedding layer of your own that can work in the place of the original  `CategoricalFeatureEmbedding` layer or any other layer for that matter. This is especially useful, if you're a desinging a new architecture and want to rapidly test out new modifications of the existing architectures by just plugging certain custom layers of your own in place of the default ones. Pretty cool, right?\n",
    "\n",
    "    2. In many cases, to reduce the plethora of parameters and keep the most important ones, some parameters specific to sub-layers, models are not offered at the top level of the given architecture by the Parametric API, so if you need to tweak those parameters missing from the main model, you can use LayerFlow API and create an instance of that layer/model with desired parameters and pass it to the model.\n",
    "\n",
    "    3. There are no seperate model classer for Regression and Classification, there's just one model class whose `head` parameter's value determines the task at hand. Like for classification, we'll pass an instance of `ClassificationHead` layer or any custom layer for that purpose.\n",
    "\n",
    "    Please note that, you are required to pass values for all parameters when using the LayerFlow API.\n",
    "\n",
    "    Now enough with theory, let's put things into practice!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using default API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 18:33:19.171749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [48842]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-08-28 18:33:19.172323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [48842]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 51s 745ms/step - loss: 0.4318 - accuracy: 0.7884\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from teras.models import TabTransformerClassifier\n",
    "\n",
    "# since there are 14 input featurs in the input dataset so the input_dim = 14\n",
    "model = TabTransformerClassifier(num_classes=2,\n",
    "                                input_dim=14,\n",
    "                                features_metadata=metadata)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(adult_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LayerFlow API\n",
    "Let's now use LayerFlow API and customize the `head` layer a bit before plugging it with the rest of the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 45s 648ms/step - loss: 0.4146 - accuracy: 0.7953\n"
     ]
    }
   ],
   "source": [
    "from teras.layerflow.models import TabTransformer\n",
    "from teras.layers import (TabTransformerColumnEmbedding,\n",
    "                          CategoricalFeatureEmbedding,\n",
    "                          Encoder,\n",
    "                          NumericalFeatureNormalization,\n",
    "                          ClassificationHead)\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "\n",
    "categorical_feature_embedding = CategoricalFeatureEmbedding(features_metadata=metadata,\n",
    "                                                            embedding_dim=EMBEDDING_DIM,\n",
    "                                                            encode=False)\n",
    "col_embedding = TabTransformerColumnEmbedding(num_categorical_features=len(categorical_feats),\n",
    "                                              embedding_dim=EMBEDDING_DIM)\n",
    "encoder = Encoder(embedding_dim=EMBEDDING_DIM)\n",
    "numerical_normalization = NumericalFeatureNormalization(features_metadata=metadata,\n",
    "                                                        normalization=\"layer\")\n",
    "head = ClassificationHead(num_classes=2)\n",
    "\n",
    "model_lf = TabTransformer(input_dim=14,\n",
    "                          categorical_feature_embedding=categorical_feature_embedding,\n",
    "                          column_embedding=col_embedding,\n",
    "                          encoder=encoder,\n",
    "                          numerical_feature_normalization=numerical_normalization,\n",
    "                          head=head)\n",
    "model_lf.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "                 loss=keras.losses.BinaryCrossentropy(),\n",
    "                 metrics=\"accuracy\")\n",
    "history = model_lf.fit(adult_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappin it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that wraps up our classification tutorial using Teras.\n",
    "If you need more help, consult documentation, and other available resources and if that still leaves you with questions, feel free to raise an issue or email me khawaja.abaid@gmail.com\n",
    "\n",
    "If you find `Teras` useful, please consider giving it a star on GitHub and sharing it with others! Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
