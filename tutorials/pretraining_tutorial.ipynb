{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teras Pretraining Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, I'll walk you through how to pretrain a model using Teras.\n",
    "\n",
    "**Model**: `TabNetRegressor`\n",
    "\n",
    "**Dataset**: Gemstone dataset (from Kaggle)\n",
    "\n",
    "**Task**: Regression using pretrained model\n",
    "\n",
    "\n",
    "**NOTE**: This tutorial is for those architectures that offer the pretraining capability and their custom pretraining architectures.\n",
    "There is no one-for-all pretraining class in Teras as every architecture that incorporates pretraining has its own pretraining approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z  price\n",
       "0   1.52    Premium     F     VS2   62.2   58.0  7.27  7.33  4.55  13619\n",
       "1   2.03  Very Good     J     SI2   62.0   58.0  8.06  8.12  5.05  13387\n",
       "2   0.70      Ideal     G     VS1   61.2   57.0  5.69  5.73  3.50   2772"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We'll use the first 10000 instances\n",
    "# We also drop the id column since that is useless\n",
    "gem_df = pd.read_csv(\"./datasets/gemstone_dataset.csv\").drop(\"id\", axis=1)[:10000]\n",
    "gem_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [\"cut\", \"color\", \"clarity\"]\n",
    "numerical_feats = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset for pretraiining and training\n",
    "TabNetPretrainer is designed for scenarios when there's lots of unlabeled data and relatively small size of labeled data.\n",
    "Though, our dataset is all labeled but for the sake of this tutorial, we'll create splits of datasets and use unlabeled split\n",
    "for pretraining and labeled split for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "training_df, pretraining_df = train_test_split(gem_df,\n",
    "                                            test_size=0.5,\n",
    "                                            shuffle=True,\n",
    "                                            random_state=1337)  # 1337 gang :D\n",
    "pretraining_df.drop(\"price\", axis=1, inplace=True) # make it unlabeled for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 19:01:41.901312: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-13 19:01:41.987041: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-13 19:01:41.988658: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 19:01:43.070799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Generate features metadata\n",
    "# Read more about what it is and why do we need it in the\n",
    "# Section 1 of General Guidelines and FAQs notebook in the tutorials directory\n",
    "from teras.utils import get_features_metadata_for_embedding\n",
    "\n",
    "metadata_pretraining = get_features_metadata_for_embedding(pretraining_df,\n",
    "                                                           categorical_features=categorical_feats,\n",
    "                                                           numerical_features=numerical_feats)\n",
    "\n",
    "metadata_training = get_features_metadata_for_embedding(training_df,\n",
    "                                                        categorical_features=categorical_feats,\n",
    "                                                        numerical_features=numerical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dataframe to tensorflow dataset of dictionary format\n",
    "# Read more about why and when we need to convert it into dictionary format in the\n",
    "# Section 2 of General Guidelines and FAQs notebook in the tutorials directory \n",
    "from teras.utils import dataframe_to_tf_dataset\n",
    "\n",
    "pretraining_ds = dataframe_to_tf_dataset(pretraining_df, as_dict=True)\n",
    "training_ds = dataframe_to_tf_dataset(training_df, target=\"price\", as_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now usually we an architecture's Classifier or Regressor model for the task at hand, but for pretraining, instead of using those, we use a base model class of that architecture.\n",
    "\n",
    "In this case, we want to first pretrain and then finetune a `TabNetRegressor` model but to do that, we'll first pretrain a base `TabNet` model. This may sound like an extra step but you'll soon see why we do it and how it helps us avoid any pitfalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the base TabNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abaid/miniconda3/envs/ML/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/abaid/miniconda3/envs/ML/lib/python3.10/site-packages/numpy/core/numeric.py:2463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "from teras.models import TabNet\n",
    "\n",
    "# Since we want to encode categorical string values \n",
    "# so we set the encode_categorical_values flag to True\n",
    "# We leave everything else to their default values\n",
    "base_model = TabNet(features_metadata=metadata_pretraining,\n",
    "                    encode_categorical_values=True,\n",
    "                    virtual_batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the TabNetPretrainer class\n",
    "\n",
    "To pretrain a base `TabNet` model, there's a `TabNetPretrainer` model that accepts a base model as arguments along with any architecture specific parameters for pretraining and is just a `keras model` which you can `compile` and `fit` like you do for any other keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.models import TabNetPretrainer\n",
    "\n",
    "# We'll leave other parameters values as default\n",
    "# for this tutorial but feel free to experiment\n",
    "pretrainer = TabNetPretrainer(model=base_model)\n",
    "\n",
    "# For custom architectures like these, which employ custom\n",
    "# loss functions, `Teras` has default values in place.\n",
    "# So unless you understand the underlying structure of\n",
    "# the pretrainer arhcitecture, it's better to just use\n",
    "# the default loss.\n",
    "# Though you can specify any optimizer.\n",
    "# Read more in the \n",
    "# Section 4 of General Guidelines and FAQs notebook in tutorial directory.\n",
    "pretrainer.compile()\n",
    "\n",
    "history = pretrainer.fit(pretraining_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TabNetRegressor instance using a pretrained base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a TabNetRegressor model instance using the pretrained base TabNet model, we first need to retrieve that pretrained model from teh TabNetPretrainer instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_base = pretrainer.pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabNetRegressor` (and any other model for that matter that is part of an architecture that offers pretraining capabilities) offers a .`from_pretrained` class method takes in the pretrained base and returns an instance of `TabNetRegressor` using that pretrained base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teras.models import TabNetRegressor\n",
    "\n",
    "regressor = TabNetRegressor.from_pretrained(pretrained_model=pretrained_base,\n",
    "                                            num_outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned instance is **NOT** compiled automatically â€” for obvious reasons to allow user the flexibility to freeze compile train, unfreeze compile train, you know the typical fine-tuning workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the regression head only!\n",
    "Let's first freeze the pretrained base, and train the Regression head of the TabNetRegressor for a few epochs before we train the whole model as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 19:02:10.593278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype double and shape [5000]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-07-13 19:02:10.594293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [5000]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 8s 17ms/step - loss: 33435854.0000 - mae: 4032.5295\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33430234.0000 - mae: 4031.8303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ab6315ab0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_base.trainable = False\n",
    "regressor.compile(loss=\"mse\", metrics=[\"mae\"])\n",
    "regressor.fit(training_ds, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model as a whole!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 17s 76ms/step - loss: 33386908.0000 - mae: 4026.5757\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 33369234.0000 - mae: 4025.0244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ab6315570>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_base.trainable = True\n",
    "regressor.compile(loss=\"mse\", metrics=[\"mae\"])\n",
    "regressor.fit(training_ds, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappin it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that wraps up our pretraining tutorial using Teras.\n",
    "\n",
    "If you need more help, consult documentation, and other available resources and if that still leaves you with questions, feel free to raise an issue or email me khawaja.abaid@gmail.com\n",
    "\n",
    "If you find `Teras` useful, please consider giving it a star on GitHub and sharing it with others!\n",
    "\n",
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
